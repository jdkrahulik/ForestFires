{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Forest Fires\n",
    "\n",
    "\n",
    "In this notebook I will explore different machine learning regression algorithms to see how well they can predict forest fire outcomes. In this notebook I will examine the different merits and drawbacks of using multiple linear regression, polynomial regression, SVM regression, and random forest regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "The dataset is supplied by:\n",
    "\n",
    "    P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. \n",
    "    In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, \n",
    "    Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December,\n",
    "    Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. \n",
    "    Available at: http://www.dsi.uminho.pt/~pcortez/fires.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area\n",
       "0  7  5   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0\n",
       "1  7  4   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0\n",
       "2  7  4   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0\n",
       "3  8  6   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0\n",
       "4  8  6   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set path\n",
    "path = 'forestfires.csv'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_qtr = {'jan': 1, 'feb': 1, 'mar': 1, \n",
    "                'apr': 2, 'may': 2, 'jun': 2, \n",
    "                'jul': 3, 'aug': 3, 'sep': 3, \n",
    "                'oct': 4, 'nov': 4, 'dec': 4}\n",
    "\n",
    "data['month'] = data['month'].apply(lambda x: month_to_qtr[x])\n",
    "data = data.rename(columns={'month': 'qtr'}).astype(dtype={'qtr': 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following attributes:\n",
    " 1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    " 2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    " 3. month - month of the year: \"jan\" to \"dec\" \n",
    " 4. day - day of the week: \"mon\" to \"sun\"\n",
    " 5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    " 6. DMC - DMC index from the FWI system: 1.1 to 291.3 \n",
    " 7. DC - DC index from the FWI system: 7.9 to 860.6 \n",
    " 8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    " 9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    " 10. RH - relative humidity in %: 15.0 to 100\n",
    " 11. wind - wind speed in km/h: 0.40 to 9.40 \n",
    " 12. rain - outside rain in mm/m2 : 0.0 to 6.4 \n",
    " 13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    " \n",
    "The data has two categorical attributes--month and day--for now I will one-hot encode them. It will be determined later whether or not they are statistically relevant to the regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First separate independent from dependent variables\n",
    "# Then one-hot encode X\n",
    "X = pd.get_dummies(data.iloc[:, :-1], drop_first=True).values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "# X.shape = (517, 19)\n",
    "# y.shape = (517,)\n",
    "\n",
    "# VERIFIED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessing modules\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features in X.  \n",
    "I will do this by implementing an sklearn pipeline. If there are any missing data points in the numeric features, they will be imputed with the mean of the column then standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X into numeric and categorical features\n",
    "X_num = X[:, :10]\n",
    "X_cat = X[:, 10:]\n",
    "\n",
    "# Setup numeric transformer\n",
    "# This will usually entail handling missing variables then scaling\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, list(range(0,X_num.shape[1])))], \n",
    "                                            remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let X equal preprocessed version of X \n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Take natural_log(y+1) for each element\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 413\n",
      "Test Data:     104\n"
     ]
    }
   ],
   "source": [
    "# Tweak test_size if applicable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print('Training Data: %3d' % len(X_train))\n",
    "print('Test Data: %7d' % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All X features are scaled and y has been transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, export the dataset as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv('ForestFires_XTrain.txt', index=False)\n",
    "pd.DataFrame(X_test).to_csv('ForestFires_XTest.txt', index=False)\n",
    "pd.DataFrame(y_train).to_csv('ForestFires_yTrain.txt', index=False)\n",
    "pd.DataFrame(y_test).to_csv('ForestFires_yTest.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_root]",
   "language": "python",
   "name": "conda-env-conda_root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
